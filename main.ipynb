{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuraChat: Smart Mental Health Companion\n",
    "\n",
    "## Description:\n",
    "An empathetic chatbot designed to provide emotional support, mindfulness exercises, and crisis management.\n",
    "\n",
    "## How It Works:\n",
    "- Users can share their feelings (e.g., \"I'm feeling stressed\"), and the chatbot provides tailored mindfulness exercises or motivational quotes.\n",
    "- Tracks user mood over time using short-term memory.\n",
    "- For critical situations, escalates the conversation to a human counselor.\n",
    "\n",
    "## LangGraph Topics Covered:\n",
    "- **State Schemas**: Define workflows for different mental health scenarios (e.g., stress, anxiety, motivation).\n",
    "- **Conditional Edges**: Route conversations based on sentiment (positive, neutral, negative).\n",
    "- **Short-Term Memory**: Track user mood and personalize interactions.\n",
    "- **Streaming**: Provide real-time mindfulness exercises.\n",
    "\n",
    "## LangSmith Topics Covered:\n",
    "- Debug workflows for crisis management using breakpoints.\n",
    "- Test chatbot responses for empathy and relevance using tracing tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Imports\n",
    "### Import necessary libraries for the chatbot workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import ollama\n",
    "import logging  \n",
    "from typing import List, Dict\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Logging Configuration\n",
    "### Configure logging to track events and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Sentiment Enum\n",
    "### Define an enumeration for sentiment analysis categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(str, Enum):\n",
    "    NEGATIVE = \"negative\"\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL = \"neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ChatState Model\n",
    "### This class represents the state of the chatbot, including messages, sentiment, summary, feedback, and user input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(BaseModel):\n",
    "    messages: List[Dict[str, str]] = []  \n",
    "    sentiment: Sentiment = Sentiment.NEUTRAL  \n",
    "    summary: str = \"\"  \n",
    "    feedback: str = \"\"  \n",
    "    user_input: str = \"\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Sentiment Analysis Function\n",
    "### This function analyzes the sentiment of a given message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(message: str) -> Sentiment:\n",
    "    try:\n",
    "        if any(word in message.lower() for word in [\"sad\", \"depressed\", \"anxious\", \"upset\"]):\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif any(word in message.lower() for word in [\"happy\", \"excited\", \"joyful\"]):\n",
    "            return Sentiment.POSITIVE\n",
    "        return Sentiment.NEUTRAL\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error analyzing sentiment: {e}\")\n",
    "        return Sentiment.NEUTRAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Response Function\n",
    "### This function generates a chatbot response using Ollama and updates the state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(state: ChatState) -> ChatState:\n",
    "    user_input = state.user_input.strip()  # Extract user input from state\n",
    "\n",
    "    if not user_input:\n",
    "        logging.warning(\"Empty user input received.\")\n",
    "        return state  # Return state unchanged\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "\n",
    "        new_state = state.model_copy()\n",
    "        new_state.messages.append({\"user\": user_input, \"bot\": response[\"message\"][\"content\"]})\n",
    "        new_state.sentiment = analyze_sentiment(user_input)\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in chatbot response: {e}\")\n",
    "        return state  # Return previous state if an error occurs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Summarization Function\n",
    "### This function summarizes the chat history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state: ChatState) -> ChatState:\n",
    "    try:\n",
    "        messages_text = \"\\n\".join([msg[\"user\"] + \" \" + msg[\"bot\"] for msg in state.messages])\n",
    "        summary = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": \"Summarize this conversation: \" + messages_text}])\n",
    "\n",
    "        new_state = state.model_copy()\n",
    "        new_state.summary = summary[\"message\"][\"content\"]\n",
    "\n",
    "        return new_state\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error summarizing conversation: {e}\")\n",
    "        return state  # Return previous state if an error occurs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sentiment Routing Function\n",
    "### This function determines the chatbot's response path based on sentiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_by_sentiment(state: ChatState):\n",
    "    if state.sentiment == Sentiment.NEGATIVE:\n",
    "        return \"negative_response\"\n",
    "    elif state.sentiment == Sentiment.POSITIVE:\n",
    "        return \"positive_response\"\n",
    "    return \"neutral_response\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Workflow Definition\n",
    "### Define the chatbot workflow using LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(ChatState)\n",
    "\n",
    "workflow.add_node(\"chatbot\", chatbot_response)\n",
    "workflow.add_node(\"summarize\", summarize_conversation)\n",
    "workflow.add_node(\"negative_response\", chatbot_response)\n",
    "workflow.add_node(\"positive_response\", chatbot_response)\n",
    "workflow.add_node(\"neutral_response\", chatbot_response)\n",
    "\n",
    "# âœ… **Register `route_by_sentiment` as a decision node**\n",
    "workflow.add_conditional_edges(\"chatbot\", route_by_sentiment)\n",
    "\n",
    "# âœ… **Connect all sentiment responses to summarization**\n",
    "workflow.add_edge(\"negative_response\", \"summarize\")\n",
    "workflow.add_edge(\"positive_response\", \"summarize\")\n",
    "workflow.add_edge(\"neutral_response\", \"summarize\")\n",
    "\n",
    "workflow.set_entry_point(\"chatbot\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Chatbot\n",
    "### The chatbot runs in a loop, taking user input and generating responses until interrupted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 02:12:10,034 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-16 02:13:18,407 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-16 02:16:12,037 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-16 02:16:12,043 - INFO - Bot: I'm so sorry to hear that you're feeling sad. It's totally okay to feel that way, and I'm here to listen and offer some support.\n",
      "\n",
      "Can you tell me a little bit more about what's going on and why you're feeling down? Sometimes talking about it can help, or we can brainstorm together to find ways to lift your mood.\n",
      "\n",
      "Remember, you're not alone, and I'm here for you. Sending you lots of positive vibes and a big virtual hug!\n",
      "2025-03-16 02:16:12,045 - INFO - [Mood: Sentiment.NEGATIVE]\n",
      "\n",
      "2025-03-16 02:17:36,703 - WARNING - Empty user input received.\n",
      "2025-03-16 02:17:36,708 - WARNING - Empty user input received.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    state = ChatState()\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \")\n",
    "            state.user_input = user_input  # âœ… Store user input in state\n",
    "        \n",
    "            # ðŸ”¹ Run decision-based workflow\n",
    "            result = graph.invoke(state)\n",
    "            if isinstance(result, ChatState):\n",
    "                state = result\n",
    "            else:\n",
    "                state = ChatState(**result)\n",
    "\n",
    "            logging.info(f\"Bot: {state.messages[-1]['bot']}\")\n",
    "            logging.info(f\"[Mood: {state.sentiment}]\\n\")\n",
    "        except KeyboardInterrupt:\n",
    "            logging.info(\"Chatbot terminated by user.\")\n",
    "            logging.info(\"\\nGoodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error in main loop: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
